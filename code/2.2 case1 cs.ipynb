{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function as fu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TelcoChurn.csv')\n",
    "\n",
    "for i in range(len(list(df[\"tenure\"]))):\n",
    "    if df[\"tenure\"][i]== 0:\n",
    "        df[\"TotalCharges\"][i] = \"0.00\"\n",
    "\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], downcast=\"float\")\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col].replace({'Yes':1},inplace=True)\n",
    "    df[col].replace({'No':0},inplace=True)\n",
    "    df[col].replace({'Female':1},inplace=True)\n",
    "    df[col].replace({'Male':0},inplace=True)\n",
    "    df[col].replace({'No phone service':2},inplace=True)\n",
    "    df[col].replace({'No internet service':2},inplace=True)\n",
    "    df[col].replace({'DSL':1},inplace=True)\n",
    "    df[col].replace({'Fiber optic':2},inplace=True)\n",
    "    df[col].replace({'Month-to-month':0},inplace=True)\n",
    "    df[col].replace({'One year':1},inplace=True)\n",
    "    df[col].replace({'Two year':2},inplace=True)\n",
    "    df[col].replace({'Electronic check':0},inplace=True)\n",
    "    df[col].replace({'Mailed check':1},inplace=True)\n",
    "    df[col].replace({'Bank transfer (automatic)':2},inplace=True)\n",
    "    df[col].replace({'Credit card (automatic)':3},inplace=True)\n",
    "\n",
    "X = df.drop('Churn',axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=18)\n",
    "\n",
    "customer = X_train[\"customerID\"]\n",
    "customertest = X_test[\"customerID\"]\n",
    "\n",
    "X_train = X_train.drop(['customerID'],axis=1)\n",
    "X_test = X_test.drop(['customerID'],axis=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "df_trans = df[['tenure', 'MonthlyCharges',\n",
    "               'TotalCharges', 'Churn']].copy(deep=True)\n",
    "for col in list(df.columns):\n",
    "    if col not in ['tenure', 'MonthlyCharges', 'TotalCharges', 'Churn'] and df[col].nunique() < 5:\n",
    "        dummy_vars = pd.get_dummies(df[col])\n",
    "        dummy_vars.columns = [col+ '_' + str(x) for x in dummy_vars.columns]        \n",
    "        df_trans = pd.concat([df_trans, dummy_vars], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1058, 351)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "D_n, D_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 21:42:07.951213: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-05-23 21:42:07.951245: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-23 21:42:07.951267: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c0709a-s29.ufhpc): /proc/driver/nvidia/version does not exist\n",
      "2023-05-23 21:42:07.951480: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 8s, sys: 31.6 s, total: 5min 39s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_list = [2,4,6,8,10]\n",
    "N_list = [[0.2, 0.5], [0.9,1.1], [1.5, 1.8]]\n",
    "N_list1 = [[0.1, 0.8], [0.2,0.5] , [0.6, 1.1]  , [0.7, 1] , [0.8, 1.2], [0.8, 1.4], [0.9,1.4] , [1, 1.1],  [1, 1.2] , [1.1,1.3], [1.5, 1.8] ]\n",
    "#N_list = [ [35,280], [70,175], [280,421], [280,491], [315,386],  [526,631], [210 , 386] , [245, 351] , [315, 491] , [351, 421], [386, 456] ]\n",
    "for N1_ratio,N2_ratio in N_list1:\n",
    "    N1= int(np.unique(y_test, return_counts = True)[1][1] * N1_ratio)\n",
    "    N2= int(np.unique(y_test, return_counts = True)[1][1] * N2_ratio)\n",
    "    \n",
    "    list_con_mat = []\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_number = []\n",
    "    list_precision = []\n",
    "    list_recall = []\n",
    "    list_f1 = []\n",
    "    list_auc = []\n",
    "    list_mcc = []\n",
    "    list_gmean = []\n",
    "\n",
    "    for p in p_list:\n",
    "        con_mat,cost, number, precision, recall, f1, auc,mcc, gmean = algorithm_cs(p, N1 = N1,N2 = N2)\n",
    "        list_p.append(p)\n",
    "        list_cost.append(cost)\n",
    "        list_number.append(number)\n",
    "        list_precision.append(precision)\n",
    "        list_recall.append(recall)\n",
    "        list_f1.append(f1)\n",
    "        list_con_mat.append(con_mat)\n",
    "        list_auc.append(auc)\n",
    "        list_mcc.append(mcc)\n",
    "        list_gmean.append(gmean)\n",
    "\n",
    "        \n",
    "    dict = {'p': list_p, 'num1':list_number, 'con_mat':list_con_mat, 'cost': list_cost, 'list_precision':list_precision, 'list_recall':list_recall, 'list_f1':list_f1,\n",
    "           'list_auc': list_auc, 'list_mcc': list_mcc, 'list_gmean': list_gmean}   \n",
    "\n",
    "    df = pd.DataFrame(dict) \n",
    "    method = 'cs'\n",
    "    # saving the dataframe \n",
    "    df.to_csv('result/case1/result_{}_{}_{}.csv'.format(method,N1,N2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tempfile\n",
    "import copy\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from random import SystemRandom    \n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "c_10 = 1\n",
    "c_01 = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "def algorithm(X_train,y_train,X_test,y_test, initial_p, times, print_per_num, total_run, N1, N2):\n",
    "    \n",
    "\n",
    "    #initiate\n",
    "    list_minp = []\n",
    "    list_mincost = []\n",
    "    list_num1 = []\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_opt_cost = []\n",
    "    list_precision = []\n",
    "    list_recall = []\n",
    "    list_f1 = []\n",
    "    list_point = []\n",
    "    list_conmat = []\n",
    "    list_auc = []\n",
    "    list_mcc = []\n",
    "    list_gmean = []\n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "\n",
    "    y_pred0 = Model(1,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fpr_fnr(y_pred0, y_test)\n",
    "    (interfpr0, interfnr0, threshold,d) = find_cost_intersection(c_01,y_test, fpr, fnr, thresholds)\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "    initial_cost= c_01 * interfnr0 * D_p + c_10 * interfpr0 * D_n\n",
    "\n",
    "    rho = 0.07\n",
    "    b = 1.6\n",
    "\n",
    "    for j in range(times):\n",
    "        p = initial_p\n",
    "        t= 80\n",
    "        alpha = 0.9\n",
    "        C_right = initial_cost\n",
    "        C_left = initial_cost\n",
    "        C_feasible = initial_cost\n",
    "        \n",
    "        num = num+1\n",
    "\n",
    "\n",
    "        p_new = p\n",
    "        p_max = 10\n",
    "        p_min = 0\n",
    "\n",
    "        delta = 0\n",
    "        C_last = 0\n",
    "        delta_rho = 0\n",
    "\n",
    "        # -----------------------------\n",
    "\n",
    "        N =total_run\n",
    "\n",
    "\n",
    "\n",
    "        #print('{} times'.format(j))\n",
    "        \n",
    "        for i in range(1,N+1):\n",
    "            y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "\n",
    "            # 1\n",
    "            fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "            (interfpr, interfnr, threshold,d) = find_cost_intersection(c_01,y_test, fpr, fnr, thresholds)\n",
    "            (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "            number_of_1 = D_n * interfpr + D_p * (1-interfnr)\n",
    "\n",
    "            # 2\n",
    "            # left\n",
    "            if interfpr < interfpr1:\n",
    "\n",
    "                case = 'left'\n",
    "                interfpr = interfpr1\n",
    "                interfnr = interfnr1\n",
    "\n",
    "                C= int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "                C_left = min(C, C_left)\n",
    "\n",
    "\n",
    "            # right\n",
    "            elif interfpr2 < interfpr:\n",
    "\n",
    "                case = 'right'\n",
    "                interfpr = interfpr2\n",
    "                interfnr = interfnr2\n",
    "\n",
    "                C= int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "                C_right = min(C, C_right)\n",
    "\n",
    "\n",
    "            # center\n",
    "            elif interfpr1<= interfpr <= interfpr2:\n",
    "                interfpr, interfnr,thresholds = find_cost_intersection_within(c_01,y_test, fpr, fnr, thresholds,N1,N2)\n",
    "                C= int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "                C_feasible = min(C_feasible, C)\n",
    "                case = 'center'\n",
    "\n",
    "\n",
    "            # 3\n",
    "            t = alpha * t\n",
    "\n",
    "            # 4\n",
    "            C_opt = min(C_left, C_right, C_feasible)\n",
    "\n",
    "            # 5        \n",
    "            delta_C = C - C_last \n",
    "\n",
    "            # 6\n",
    "            probability = (C_right + 0.5 * C_feasible) / (C_right + C_left + C_feasible) \n",
    "\n",
    "            # 9\n",
    "            probability2 = np.exp(-delta_C / t)\n",
    "            if delta_C <= 0 or ( delta_C > 0 and  probability2 > SystemRandom().random() ):\n",
    "\n",
    "                # 7\n",
    "\n",
    "                delta_rho = (1 - rho  ** ( (1 - (i/N) ) ** b ) )\n",
    "                if probability <= SystemRandom().random():\n",
    "                    delta = (p - p_min) *  delta_rho  # 8\n",
    "                    p_new = p - delta\n",
    "                else:\n",
    "                    delta = (p_max - p) * delta_rho   # 8\n",
    "                    p_new = p + delta\n",
    "\n",
    "\n",
    "            C_last = C\n",
    "\n",
    "            list_p.append(p)\n",
    "            list_cost.append(C)\n",
    "            p = p_new\n",
    "        \n",
    "        min_cost = min(list_cost)\n",
    "        min_p = list_p[list_cost.index(min_cost)]\n",
    "        y_pred = Model(min_p,X_train, y_train, X_test, y_test)\n",
    "        fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "        number_of_1,precision,recall,f1, auc,mcc, gmean, con_mat,interfpr,interfnr,cost,opt_cost = metrics(min_p,fpr, fnr, thresholds,N1,N2,X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        \n",
    "        min_p = np.round(min_p,5)\n",
    "        list_minp.append(min_p)\n",
    "        list_mincost.append(cost)\n",
    "        list_opt_cost.append(opt_cost)\n",
    "        list_num1.append(number_of_1)\n",
    "\n",
    "        list_precision.append(precision)\n",
    "        list_recall.append(recall)\n",
    "        list_f1.append(f1)\n",
    "        list_auc.append(auc)\n",
    "        list_mcc.append(mcc)\n",
    "        list_gmean.append(gmean)\n",
    "        \n",
    "        list_point.append((interfpr, interfnr))\n",
    "        list_conmat.append(con_mat)\n",
    "        \n",
    "        \n",
    "    \n",
    "    dict = {'p': list_minp, 'cost': list_mincost, 'num1': list_num1, 'list_conmat': list_conmat, 'list_point': list_point, 'list_precision':list_precision, 'list_recall':list_recall, 'list_f1':list_f1, 'list_auc': list_auc, 'list_mcc': list_mcc, 'list_gmean': list_gmean, 'list_opt_cost':list_opt_cost}\n",
    "    \n",
    "    df = pd.DataFrame(dict) \n",
    "    method = 'ondemand'\n",
    "    # saving the dataframe \n",
    "    df.to_csv('result/case1/result_{}_{}_{}_{}.csv'.format(method,N1,N2,initial_p,))\n",
    "    \n",
    "    \n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "def metrics(p, fpr, fnr, thresholds,N1,N2,X_train, y_train, X_test, y_test):\n",
    "    y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    # 1\n",
    "    (interfpr, interfnr, threshold,d) = find_cost_intersection(c_01, y_test, fpr, fnr, thresholds)\n",
    "    (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "    \n",
    "    interfpr, interfnr, threshold = find_cost_intersection_within(c_01,y_test, fpr, fnr, thresholds,N1,N2)\n",
    "    \n",
    "    y_pred_copy = copy.copy(y_pred)\n",
    "    y_result = np.where(y_pred_copy>threshold,1,0)\n",
    "    \n",
    "    number_of_1 = D_n * interfpr + D_p * (1-interfnr)\n",
    "    number_of_1 = round(number_of_1)\n",
    "    \n",
    "    y_result = np.where(y_pred >= threshold, 1, 0)\n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "    \n",
    "    cost = int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "    optimal_cost = round(c_01 * D_p *d)\n",
    "    \n",
    "\n",
    "    if N2 < number_of_1:\n",
    "        count = 0\n",
    "        ticket = False\n",
    "        sum1 = sum(np.where(y_pred>threshold,1,0))\n",
    "        target = N2 - sum1\n",
    "        y_pred_copy = copy.copy(y_pred)\n",
    "\n",
    "        for j in range(len(y_pred)):\n",
    "            if y_pred[j] == threshold:\n",
    "                y_pred_copy[j] = 1\n",
    "                count +=1\n",
    "\n",
    "            if count == target:\n",
    "                ticket = True\n",
    "                break\n",
    "\n",
    "        if ticket == True:\n",
    "            y_result = np.where(y_pred_copy >threshold,1,0)\n",
    "            con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "            TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "            number_of_1 = FP + TP\n",
    "\n",
    "    if N2 < number_of_1 and N1 < D_p and D_p < N2: #50,150\n",
    "        count = 0\n",
    "        ticket = False\n",
    "        sum1 = sum(np.where(y_pred>threshold,1,0))\n",
    "        target = N2 - sum1\n",
    "        y_pred_copy = copy.copy(y_pred)\n",
    "        cost_list = []\n",
    "        con_mat_list = []\n",
    "\n",
    "        for j in range(len(y_pred)):\n",
    "            if y_pred[j] == threshold:\n",
    "                y_pred_copy[j] = 1\n",
    "                count +=1\n",
    "                y_result = np.where(y_pred_copy >threshold,1,0)\n",
    "                TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "                if FP + TP >N1:\n",
    "                    cost = FP * c_10 + FN * c_01\n",
    "                    con_mat_list.append(confusion_matrix(y_test, y_result).T.flatten().tolist())\n",
    "                    cost_list.append(cost)\n",
    "\n",
    "            if count == target:\n",
    "                ticket = True\n",
    "            break\n",
    "\n",
    "        if ticket == True:\n",
    "            y_result = np.where(y_pred >threshold,1,0)\n",
    "            con_mat = con_mat_list[cost_list.index(min(cost_list))]\n",
    "            cost = min(cost_list)\n",
    "            TN, FN, FP, TP = con_mat\n",
    "            number_of_1 = FP + TP    \n",
    "        \n",
    "    p = round(precision_score(y_test, y_result),3)\n",
    "    r = round(recall_score(y_test, y_result),3)\n",
    "    f = round(f1_score(y_test, y_result),3)\n",
    "    auc = 1- round(roc_auc_score(y_test, y_result),3)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),3)\n",
    "    \n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    \n",
    "    return number_of_1, p,r,f, auc,mcc, gmean, con_mat, interfpr,interfnr,cost,optimal_cost\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def find_limit_point(fpr, fnr, thresholds,N1,N2):\n",
    "    (interfpr1,interfnr1,threshold1) = (fpr[N1-1], fnr[N1-1], thresholds[N1-1])\n",
    "    (interfpr2,interfnr2,threshold2) = (fpr[N2-1], fnr[N2-1], thresholds[N2-1])\n",
    "    \n",
    "    return (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def find_cost_intersection(c_01,y_test, fpr, fnr, thresholds):\n",
    "    list_distance = []\n",
    "    norm = np.linalg.norm\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "    k =0.000001\n",
    "    for j in range(len(fpr)):\n",
    "        p1 = np.array([0,k])\n",
    "        p2 = np.array([(D_p/D_n)*c_01*k, 0])\n",
    "\n",
    "        p3 = np.array([fpr[j], fnr[j]])\n",
    "\n",
    "        distance = np.abs(norm(np.cross(p2-p1, p1-p3)))/norm(p2-p1)\n",
    "        list_distance.append(distance)\n",
    "    index = list_distance.index(min(list_distance))\n",
    "\n",
    "    return fpr[index], fnr[index], thresholds[index],min(list_distance)\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def find_cost_intersection_within(c_01,y_test, fpr, fnr, thresholds,N1,N2):\n",
    "    \n",
    "    (interfpr1,interfnr1,threshold1) = (fpr[N1-1], fnr[N1-1], thresholds[N1-1])\n",
    "    (interfpr2,interfnr2,threshold2) = (fpr[N2-1], fnr[N2-1], thresholds[N2-1])\n",
    "\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    list_distance = []\n",
    "    norm = np.linalg.norm\n",
    "\n",
    "    k =0.00001\n",
    "    for j in range(N1-1, N2):\n",
    "        p1 = np.array([0,k])\n",
    "        p2 = np.array([(D_p/D_n)*c_01*k, 0])\n",
    "\n",
    "        p3 = np.array([fpr[j], fnr[j]])\n",
    "\n",
    "        distance = np.abs(norm(np.cross(p2-p1, p1-p3)))/norm(p2-p1)\n",
    "        list_distance.append(distance)\n",
    "\n",
    "    index = list_distance.index(min(list_distance))\n",
    "    \n",
    "    return fpr[N1-1 + index], fnr[N1-1 + index], thresholds[N1-1 + index]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def algorithm_nn(N1,N2):\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    y_pred = Model(1,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    if D_p <= N1:\n",
    "        num = N1\n",
    "    elif N2 <= D_p:\n",
    "        num = N2\n",
    "    elif N1 < D_p < N2:\n",
    "        num = D_p\n",
    "        \n",
    "    th = sorted(y_pred, reverse = True)[num]\n",
    "    y_result = np.where(y_pred>th, 1, 0)\n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10\n",
    "\n",
    " \n",
    "    number = confusion_matrix(y_test, y_result).T[1][1] + confusion_matrix(y_test, y_result).T[1][0]       \n",
    "    p = round(precision_score(y_test, y_result),3)\n",
    "    r = round(recall_score(y_test, y_result),3)\n",
    "    f = round(f1_score(y_test, y_result),3)\n",
    "    auc = round(roc_auc_score(y_test, y_result),3)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),3)\n",
    "    \n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "\n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10 \n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    \n",
    "    return con_mat,cost, number, p, r, f, auc,mcc, gmean\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def algorithm_cs(p, N1,N2):\n",
    "\n",
    "        \n",
    "        \n",
    "    y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    if D_p <= N1:\n",
    "        num = N1\n",
    "    elif N2 <= D_p:\n",
    "        num = N2\n",
    "    elif N1 < D_p < N2:\n",
    "        num = D_p\n",
    "    \n",
    "    th = sorted(y_pred, reverse = True)[num]\n",
    "    y_result = np.where(y_pred>th, 1, 0)\n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10\n",
    "\n",
    " \n",
    "    number = confusion_matrix(y_test, y_result).T[1][1] + confusion_matrix(y_test, y_result).T[1][0]       \n",
    "    p = round(precision_score(y_test, y_result),3)\n",
    "    r = round(recall_score(y_test, y_result),3)\n",
    "    f = round(f1_score(y_test, y_result),3)\n",
    "    auc = round(roc_auc_score(y_test, y_result),3)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),3)\n",
    "    \n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    \n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10 \n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    \n",
    "    return con_mat,cost, number, p, r, f, auc,mcc, gmean\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def fpr_fnr(y_pred, y_test):\n",
    "    \n",
    "    list_fpr = []\n",
    "    list_fnr = []\n",
    "    list_th = []\n",
    "    y_pred_sort=sorted(y_pred, reverse=True)\n",
    "\n",
    "    for i in range(1,len(y_pred)+1):\n",
    "        th = y_pred_sort[i-1][0]\n",
    "        y_result = np.where(y_pred >= th,1,0)\n",
    "        tn, fn, fp, tp = confusion_matrix(y_test, y_result).T.ravel()\n",
    "        fpr = fp / (tn+fp)\n",
    "        fnr = fn / (tp+fn)\n",
    "\n",
    "        list_fpr.append(fpr)\n",
    "        list_fnr.append(fnr)\n",
    "        list_th.append(th)\n",
    "        \n",
    "    return [list_fpr, list_fnr, list_th]\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "def mid_data():\n",
    "    np.random.seed(0)\n",
    "    X =  np.random.rand(20000,12) * 20\n",
    "\n",
    "    y = []\n",
    "    for p in range(len(X)):\n",
    "\n",
    "\n",
    "        a = X[p][0] \n",
    "        b = X[p][1] \n",
    "        c = X[p][2] \n",
    "        d = X[p][3] \n",
    "        e = X[p][4] \n",
    "        f = X[p][5] \n",
    "        \n",
    "        g = math.cos(X[p][6]) * 10\n",
    "        h = math.cos(X[p][7]) * 10\n",
    "        i = math.cos(X[p][8]) * 10\n",
    "        j = math.sin(X[p][9]) * 10\n",
    "        k = math.sin(X[p][10]) * 10\n",
    "        l = math.sin(X[p][11]) * 10\n",
    "\n",
    "        sum_ = a-b+c-d+e-f+g-h+i-j+k-l\n",
    "        result = 1 if sum_ > 0 else 0\n",
    "\n",
    "        y.append(result)\n",
    "\n",
    "    df =  pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "\n",
    "    df_0 = df[df['y'] == 0][:9000]\n",
    "    df_1 = df[df['y'] == 1][:1000]\n",
    "\n",
    "    df__0 = df_0[:7200].append(df_1[:800]).sample(frac = 1).reset_index(drop = True)\n",
    "    df__1 = df_0[7200:].append(df_1[800:]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "    X_train = df__0.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_train = df__0.iloc[:, [-1]].to_numpy()\n",
    "    X_test = df__1.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_test = df__1.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "def easy_data():\n",
    "    np.random.seed(0)\n",
    "    X =  np.random.rand(20000,12) * 20\n",
    "\n",
    "    y = []\n",
    "    for p in range(len(X)):\n",
    "\n",
    "\n",
    "        a = X[p][0] \n",
    "        b = X[p][1] \n",
    "        c = X[p][2] \n",
    "        d = X[p][3] \n",
    "        e = X[p][4] \n",
    "        f = X[p][5] \n",
    "        \n",
    "        g = X[p][6] \n",
    "        h = X[p][7] \n",
    "        i = X[p][8] \n",
    "        j = X[p][9] \n",
    "        k = X[p][10] \n",
    "        l = X[p][11]\n",
    "        \n",
    "\n",
    "        sum_ = a-b+c-d+e-f+g-h+i-j+k-l\n",
    "        result = 1 if sum_ > 0 else 0\n",
    "\n",
    "        y.append(result)\n",
    "\n",
    "    df =  pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "\n",
    "    df_0 = df[df['y'] == 0][:9000]\n",
    "    df_1 = df[df['y'] == 1][:1000]\n",
    "\n",
    "    df__0 = df_0[:7200].append(df_1[:800]).sample(frac = 1).reset_index(drop = True)\n",
    "    df__1 = df_0[7200:].append(df_1[800:]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "    X_train = df__0.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_train = df__0.iloc[:, [-1]].to_numpy()\n",
    "    X_test = df__1.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_test = df__1.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def hard_data():\n",
    "    np.random.seed(0)\n",
    "    X =  np.random.rand(20000,12) * 20\n",
    "\n",
    "    y = []\n",
    "    for p in range(len(X)):\n",
    "\n",
    "\n",
    "        a = math.cos(X[p][0]) * 10\n",
    "        b = math.cos(X[p][1]) * 10\n",
    "        c = math.cos(X[p][2]) * 10\n",
    "        d = math.sin(X[p][3]) * 10\n",
    "        e = math.sin(X[p][4]) * 10\n",
    "        f = math.sin(X[p][5]) * 10 \n",
    "        \n",
    "        g = math.cos(X[p][6]) * 10\n",
    "        h = math.cos(X[p][7]) * 10\n",
    "        i = math.cos(X[p][8]) * 10\n",
    "        j = math.sin(X[p][9]) * 10\n",
    "        k = math.sin(X[p][10]) * 10\n",
    "        l = math.sin(X[p][11]) * 10\n",
    "\n",
    "        sum_ = a-b+c-d+e-f+g-h+i-j+k-l\n",
    "        result = 1 if sum_ > 0 else 0\n",
    "\n",
    "        y.append(result)\n",
    "\n",
    "    df =  pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "\n",
    "    df_0 = df[df['y'] == 0][:9000]\n",
    "    df_1 = df[df['y'] == 1][:1000]\n",
    "\n",
    "    df__0 = df_0[:7200].append(df_1[:800]).sample(frac = 1).reset_index(drop = True)\n",
    "    df__1 = df_0[7200:].append(df_1[800:]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "    X_train = df__0.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_train = df__0.iloc[:, [-1]].to_numpy()\n",
    "    X_test = df__1.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_test = df__1.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# -------------------------------------------------------------------------------------  \n",
    "    \n",
    "def reset_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED']=str(1)\n",
    "    tf.random.set_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "def Model(p, X_train,y_train,X_test,y_test):\n",
    "    reset_random_seeds()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[-1], activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train,y_train, epochs=30, shuffle = True, batch_size=32 ,class_weight =  {0: 1, 1: p}, verbose =0)\n",
    "    y_pred = model.predict(X_test, batch_size=32, verbose =0)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "def rough_plt(N1,N2):\n",
    "\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_cost_ = []\n",
    "    list_inter = []\n",
    "    list_opt = []\n",
    "    list_con1 = []\n",
    "    list_con2 = []\n",
    "\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "    for p in range(1,10,1):\n",
    "        y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "        print(p)\n",
    "\n",
    "\n",
    "        (interfpr0, interfnr0, thresholds) = find_cost_intersection(c_01,y_test,fpr, fnr, thresholds)\n",
    "        (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "\n",
    "        list_opt.append([interfpr, interfnr])\n",
    "        list_con1.append([interfpr1, interfnr1])\n",
    "        list_con2.append([interfpr2, interfnr2])\n",
    "\n",
    "        cost1 = c_01 * interfnr * D_p + c_10 * interfpr * D_n\n",
    "\n",
    "        if interfpr1 <= interfpr <= interfpr2:\n",
    "            cost = c_01 * interfnr * D_p + c_10 * interfpr * D_n\n",
    "            list_inter.append([interfpr,interfnr])\n",
    "\n",
    "        elif interfpr < interfpr1:\n",
    "            cost = c_01 * interfnr1 * D_p + c_10 * interfpr1 * D_n\n",
    "            list_inter.append([interfpr1,interfnr1])\n",
    "\n",
    "        elif interfpr2 < interfpr:\n",
    "            cost = c_01 * interfnr2 * D_p + c_10 * interfpr2 * D_n\n",
    "            list_inter.append([interfpr2,interfnr2])\n",
    "\n",
    "        list_cost.append(round(cost1))\n",
    "        list_cost_.append(round(cost))\n",
    "        list_p.append(p)\n",
    "\n",
    "    list_rank_p = []\n",
    "    list_rank_cost = []\n",
    "    for i in range(5):\n",
    "        rank = np.where(np.array(list_cost_) == sorted(list_cost_)[i])[0][0]\n",
    "\n",
    "        rank_p = list_p[rank]\n",
    "        rank_cost = list_cost_[rank]\n",
    "\n",
    "        list_rank_p.append(rank_p)\n",
    "        list_rank_cost.append(rank_cost)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(list_p,list_cost, marker='o', label='optimal')\n",
    "    plt.plot(list_p,list_cost_, marker='o', label='constraint')\n",
    "    plt.legend()\n",
    "    plt.title(f'N1:{N1}, N2:{N2}')\n",
    "    plt.xlabel(f'Best:{list_rank_p[:10]} \\n Best:{list_rank_cost[:10]}')\n",
    "    plt.savefig(f'rough {N1}, {N2}')\n",
    "    \n",
    "    return None\n",
    "# -------------------------------------------------------------------------------------   \n",
    "    \n",
    "def precise_plt(p_start, p_end,N1,N2):\n",
    "\n",
    "\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_cost_ = []\n",
    "    list_inter = []\n",
    "    list_opt = []\n",
    "    list_con1 = []\n",
    "    list_con2 = []\n",
    "\n",
    "    for p in range(p_start,p_end,1):\n",
    "        p = p/100\n",
    "\n",
    "        y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "        D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "        D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "\n",
    "        (interfpr0, interfnr0, thresholds) = find_cost_intersection(c_01,y_test, fpr, fnr, thresholds)\n",
    "        (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "\n",
    "        list_opt.append([interfpr, interfnr])\n",
    "        list_con1.append([interfpr1, interfnr1])\n",
    "        list_con2.append([interfpr2, interfnr2])\n",
    "\n",
    "        cost1 = c_01 * interfnr * D_p + c_10 * interfpr * D_n\n",
    "\n",
    "        if interfpr1 <= interfpr <= interfpr2:\n",
    "            cost = c_01 * interfnr * D_p + c_10 * interfpr * D_n  \n",
    "            list_inter.append([interfpr,interfnr])\n",
    "\n",
    "        elif interfpr < interfpr1:\n",
    "            cost = c_01 * interfnr1 * D_p + c_10 * interfpr1 * D_n\n",
    "            list_inter.append([interfpr1,interfnr1])\n",
    "\n",
    "        elif interfpr2 < interfpr:\n",
    "            cost = c_01 * interfnr2 * D_p + c_10 * interfpr2 * D_n\n",
    "            list_inter.append([interfpr2,interfnr2])\n",
    "\n",
    "        list_cost.append(round(cost1))\n",
    "        list_cost_.append(round(cost))\n",
    "        list_p.append(p)\n",
    "\n",
    "    list_rank_p = []\n",
    "    list_rank_cost = []\n",
    "    for i in range(10):\n",
    "        rank = list_cost_.index([*set(sorted(list_cost_))][i])\n",
    "\n",
    "        rank_p = list_p[rank]\n",
    "        rank_cost = list_cost_[rank]\n",
    "\n",
    "        list_rank_p.append(rank_p)\n",
    "        list_rank_cost.append(rank_cost)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(list_p,list_cost, marker='o', label='optimal')\n",
    "    plt.scatter(list_p,list_cost_, marker='o', label='constraint')\n",
    "    plt.legend()\n",
    "    plt.title(f'N1:{N1}, N2:{N2}')\n",
    "    plt.xlabel(f'Best:{list_rank_p[:10]} \\n Best:{list_rank_cost[:10]}')\n",
    "    plt.savefig(f'precise {N1}, {N2}')\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
