{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function as fu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TelcoChurn.csv')\n",
    "\n",
    "for i in range(len(list(df[\"tenure\"]))):\n",
    "    if df[\"tenure\"][i]== 0:\n",
    "        df[\"TotalCharges\"][i] = \"0.00\"\n",
    "\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], downcast=\"float\")\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col].replace({'Yes':1},inplace=True)\n",
    "    df[col].replace({'No':0},inplace=True)\n",
    "    df[col].replace({'Female':1},inplace=True)\n",
    "    df[col].replace({'Male':0},inplace=True)\n",
    "    df[col].replace({'No phone service':2},inplace=True)\n",
    "    df[col].replace({'No internet service':2},inplace=True)\n",
    "    df[col].replace({'DSL':1},inplace=True)\n",
    "    df[col].replace({'Fiber optic':2},inplace=True)\n",
    "    df[col].replace({'Month-to-month':0},inplace=True)\n",
    "    df[col].replace({'One year':1},inplace=True)\n",
    "    df[col].replace({'Two year':2},inplace=True)\n",
    "    df[col].replace({'Electronic check':0},inplace=True)\n",
    "    df[col].replace({'Mailed check':1},inplace=True)\n",
    "    df[col].replace({'Bank transfer (automatic)':2},inplace=True)\n",
    "    df[col].replace({'Credit card (automatic)':3},inplace=True)\n",
    "\n",
    "X = df.drop('Churn',axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=18)\n",
    "\n",
    "customer = X_train[\"customerID\"]\n",
    "customertest = X_test[\"customerID\"]\n",
    "\n",
    "X_train = X_train.drop(['customerID'],axis=1)\n",
    "X_test = X_test.drop(['customerID'],axis=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "df_trans = df[['tenure', 'MonthlyCharges',\n",
    "               'TotalCharges', 'Churn']].copy(deep=True)\n",
    "for col in list(df.columns):\n",
    "    if col not in ['tenure', 'MonthlyCharges', 'TotalCharges', 'Churn'] and df[col].nunique() < 5:\n",
    "        dummy_vars = pd.get_dummies(df[col])\n",
    "        dummy_vars.columns = [col+ '_' + str(x) for x in dummy_vars.columns]        \n",
    "        df_trans = pd.concat([df_trans, dummy_vars], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min, sys: 52.8 s, total: 6min 53s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "c_01 = 3\n",
    "c_10 = 1\n",
    "p_list = [2,4,6,8,10]\n",
    "N_list1 = [ [0.1, 0.8], [0.2,0.5] , [0.6, 1.1]  , [0.7, 1] , [0.8, 1.2], [0.8, 1.4], [0.9,1.4] , [1, 1.1],  [1, 1.2] , [1.1,1.3], [1.5, 1.8] ]\n",
    "for N1_ratio,N2_ratio in N_list1:\n",
    "    N1= int(np.unique(y_test, return_counts = True)[1][1] * N1_ratio)\n",
    "    N2= int(np.unique(y_test, return_counts = True)[1][1] * N2_ratio)\n",
    "        \n",
    "    list_con_mat = []\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_number = []\n",
    "    list_precision = []\n",
    "    list_recall = []\n",
    "    list_f1 = []\n",
    "    list_auc = []\n",
    "    list_mcc = []\n",
    "    list_gmean = []\n",
    "\n",
    "    for p in p_list:\n",
    "        ticket = True\n",
    "        while ticket:\n",
    "            con_mat,cost, number, precision, recall, f1, auc,mcc, gmean = algorithm_spo(c_01,p, N1,N2)\n",
    "            if not (con_mat[0] == N1) or (con_mat[-1] == N2): ticket = False\n",
    "\n",
    "        #print(f'initial_p:{p},cost:{cost},precision:{precision},recall:{recall},f1:{f1}')\n",
    "        list_p.append(p)\n",
    "        list_cost.append(cost)\n",
    "        list_number.append(number)\n",
    "        list_precision.append(precision)\n",
    "        list_recall.append(recall)\n",
    "        list_f1.append(f1)\n",
    "        list_con_mat.append(con_mat)\n",
    "        list_auc.append(auc)\n",
    "        list_mcc.append(mcc)\n",
    "        list_gmean.append(gmean)\n",
    "\n",
    "\n",
    "    dict = {'p': list_p, 'num1':list_number, 'con_mat':list_con_mat, 'cost': list_cost, 'list_precision':list_precision, 'list_recall':list_recall, 'list_f1':list_f1,\n",
    "           'list_auc': list_auc, 'list_mcc': list_mcc, 'list_gmean': list_gmean}   \n",
    "\n",
    "    df = pd.DataFrame(dict) \n",
    "    method = 'spo'\n",
    "    # saving the dataframe \n",
    "    df.to_csv('result/case1/result_{}_{}_{}.csv'.format(method,N1,N2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spo_plus_loss(c_01):\n",
    "    c_01 = tf.cast(c_01, tf.float64)\n",
    "    \n",
    "    def my_loss(y_true,y_pred):\n",
    "        #y_pred = tf.clip_by_value(y_pred, 0.0001, 1 - 0.0001)\n",
    "        y_pred = tf.cast(y_pred, tf.float64)\n",
    "        y_true = tf.cast(y_true, tf.float64)\n",
    "        \n",
    "        max_1 = tf.cast(tf.math.maximum(2 * y_pred - 1,0),tf.float64)\n",
    "        max_2 = tf.cast(tf.math.maximum(1-2 * y_pred, 0), tf.float64)\n",
    "        \n",
    "        loss =  y_pred*(1-y_pred)+ max_1 * c_01 * y_true + (1- y_true) * max_2 + c_01 * y_true * (1-2 * y_pred) + (1 - y_true) * (2*y_pred - 1)\n",
    "        #loss = tf.cast(y_true, tf.float64) * y_pred +(1-tf.cast(y_true, tf.float64)) * ( 1-y_pred)\n",
    "         \n",
    "        #if max_1 ==0: max_1 =tf.cast(1, tf.float64)\n",
    "        #if max_2 ==0: max_2 =tf.cast(1, tf.float64)\n",
    "            \n",
    "        #loss = tf.math.multiply_no_nan(x= tf.math.log(max_1), y= tf.cast(y_true, tf.float64))* c_01 +  tf.math.multiply_no_nan( x=tf.math.log(max_2), y= (1- tf.cast(y_true, tf.float64)) )*c_01\n",
    "\n",
    "        #loss = ((tf.cast(y_true, tf.float64) * (1-y_pred))*c_01 + ((1-tf.cast(y_true, tf.float64)) * y_pred ))\n",
    "                                                      \n",
    "        return loss\n",
    "    return my_loss\n",
    "\n",
    "def Model_spo(c_01,X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape = (np.array(X_train).shape[-1],)),\n",
    "    tf.keras.layers.Dense(5, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss= spo_plus_loss(c_01))\n",
    "    \n",
    "    model.fit(X_train,y_train,shuffle = True, epochs= 30,verbose =0)\n",
    "    y_pred = model.predict(X_test, batch_size=16, verbose =0)\n",
    " \n",
    "    return y_pred\n",
    "\n",
    "def algorithm_spo(c_01,p, N1,N2):\n",
    "        \n",
    "    y_pred = Model_spo(c_01,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fu.fpr_fnr(y_pred, y_test)\n",
    "\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    if D_p <= N1:\n",
    "        num = N1\n",
    "    elif N2 <= D_p:\n",
    "        num = N2\n",
    "    elif N1 < D_p < N2:\n",
    "        num = D_p\n",
    "    \n",
    "    th = sorted(y_pred, reverse = True)[num]\n",
    "    y_result = np.where(y_pred>th, 1, 0)\n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "\n",
    "    if (FP+TP) < N1:\n",
    "        ticket1 = False\n",
    "        ticket2 = False\n",
    "        count = 0\n",
    "        \n",
    "        target = N1 - (FP+TP) \n",
    "        for i in range(len(y_result)):\n",
    "            if y_result[i] ==0:\n",
    "                y_result[i] =1\n",
    "                count +=1\n",
    "            if count == target:\n",
    "                ticket1 = True\n",
    "\n",
    "            if ticket1 == True:\n",
    "                break\n",
    "\n",
    "    elif N2 < (FP+TP):\n",
    "        ticket1 = False\n",
    "        ticket2 = False\n",
    "        count = 0\n",
    "        \n",
    "        target = (FP+TP) - N2\n",
    "        for i in range(len(y_result)):\n",
    "            if y_result[i] ==1:\n",
    "                y_result[i] =0\n",
    "                count +=1\n",
    "            if count == target:\n",
    "                ticket2 = True\n",
    "\n",
    "            if ticket2 == True:\n",
    "                break\n",
    "\n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10\n",
    "    cost = round(cost)\n",
    " \n",
    "    number = confusion_matrix(y_test, y_result).T[1][1] + confusion_matrix(y_test, y_result).T[1][0]       \n",
    "    p = round(precision_score(y_test, y_result),2)\n",
    "    r = round(recall_score(y_test, y_result),2)\n",
    "    f = round(f1_score(y_test, y_result),2)\n",
    "    auc = round(roc_auc_score(y_test, y_result),2)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),2)\n",
    "    \n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    \n",
    "    return con_mat,cost, number, p, r, f, auc,mcc, gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
