{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import function as fu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/creditcard.csv')\n",
    "data.rename(columns= {'LIMIT_BAL':'given_credit',\n",
    "                       'PAY_0':'status_apr',\n",
    "                       'PAY_2':'status_may',\n",
    "                       'PAY_3':'status_jun',\n",
    "                       'PAY_4':'status_jul',\n",
    "                       'PAY_5':'status_aug',\n",
    "                       'PAY_6':'status_sep',\n",
    "\n",
    "                       'BILL_AMT1':'bill_apr',\n",
    "                       'BILL_AMT2':'bill_may',\n",
    "                       'BILL_AMT3':'bill_jun',\n",
    "                       'BILL_AMT4':'bill_jul',\n",
    "                       'BILL_AMT5':'bill_aug',\n",
    "                       'BILL_AMT6':'bill_sep',\n",
    "                       \n",
    "                       'PAY_AMT1':'pay_apr',\n",
    "                       'PAY_AMT2':'pay_may',\n",
    "                       'PAY_AMT3':'pay_jun',\n",
    "                       'PAY_AMT4':'pay_jul',\n",
    "                       'PAY_AMT5':'pay_aug',\n",
    "                       'PAY_AMT6':'pay_sep',\n",
    "                       },\n",
    "                        \n",
    "            inplace = True)\n",
    "\n",
    "# As a syntaxis rule, the rest of the column names are changed to lower case\n",
    "data.columns = data.columns.str.lower()\n",
    "\n",
    "#Blank spaces are also replaced by \"_\"\n",
    "data.columns = data.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "#Our tatget variable has a very long name, so it is shortened to \"default_payment\"\n",
    "data.rename(columns= {'default.payment.next.month':'default_payment'}, inplace = True)\n",
    "\n",
    "marriage = pd.DataFrame()\n",
    "\n",
    "#Frequency table by marriage value\n",
    "marriage[\"qty_data\"] = pd.DataFrame(data.marriage.value_counts())\n",
    "\n",
    "#Mean age by marriage value:\n",
    "marriage[\"mean_age\"] = pd.DataFrame(round(data.groupby(\"marriage\")[\"age\"].mean(),2))\n",
    "\n",
    "#Mean default_payment\n",
    "marriage[\"deafult_rate\"] = pd.DataFrame(round(data.groupby(\"marriage\")[\"default_payment\"].mean(),2))\n",
    "\n",
    "data_clean = data\n",
    "data_clean.loc[(data_clean['marriage']==0),'marriage']=3\n",
    "\n",
    "education = pd.DataFrame()\n",
    "\n",
    "#Frequency table by marriage value\n",
    "education[\"qty_data\"] = pd.DataFrame(data.education.value_counts())\n",
    "\n",
    "#Mean age by marriage value:\n",
    "education[\"mean_age\"] = pd.DataFrame(round(data.groupby(\"education\")[\"age\"].mean(),2))\n",
    "\n",
    "#Mean default_payment\n",
    "education[\"deafult_rate\"] = pd.DataFrame(round(data.groupby(\"education\")[\"default_payment\"].mean(),2))\n",
    "\n",
    "data_clean.loc[(data_clean['education']==0) | (data_clean['education']==5) | (data_clean['education']==6),\n",
    "               'education']=4\n",
    "\n",
    "status = pd.DataFrame()\n",
    "\n",
    "#Frequency table by marriage value\n",
    "status[\"qty_data\"] = pd.DataFrame(data.status_apr.value_counts())\n",
    "\n",
    "#Mean age by marriage value:\n",
    "status[\"mean_age\"] = pd.DataFrame(round(data.groupby(\"status_apr\")[\"age\"].mean(),2))\n",
    "\n",
    "#Mean default_payment\n",
    "status[\"deafult_rate\"] = pd.DataFrame(round(data.groupby(\"status_apr\")[\"default_payment\"].mean(),2))\n",
    "\n",
    "data_FE = data_clean\n",
    "#Set \"education\" as catigory type\n",
    "data_FE[\"education\"] = data_FE [\"education\"].astype(\"category\")\n",
    "\n",
    "#Creating dummy features\n",
    "edu_dummies = pd.get_dummies(data_FE['education'], prefix='edu')\n",
    "\n",
    "#Adding these new dummy variables to our dataset\n",
    "data_FE = pd.concat( [data_FE, edu_dummies] , axis = 1)\n",
    "data_FE = data_FE.drop(columns=['education']);\n",
    "\n",
    "data_FE.columns = data_FE.columns.str.replace(\",\", \"-\") # subst. \",\" for \"-\"\n",
    "data_FE.columns = data_FE.columns.str.replace(\" \", \"\")  # deleting spaces\n",
    "data_FE.columns = data_FE.columns.str.replace(\"(\", \"\")  # deleting \"(\"\n",
    "data_FE.columns = data_FE.columns.str.replace(\")\", \"\")  # deleting \")\"\n",
    "data_FE.columns = data_FE.columns.str.replace(\"]\", \"\"); # deleting \"]\"\n",
    "\n",
    "data_premod = data_FE\n",
    "# Separating into input data and target variables\n",
    "\n",
    "#Eliminating the target column from the input data\n",
    "X_original =  pd.DataFrame( data_premod.drop(columns='default_payment'))\n",
    "\n",
    "# Target varibale as independent dataframe\n",
    "Y_original = pd.DataFrame( data_premod[\"default_payment\"] )\n",
    "\n",
    "# Standard Scaler from SciKit Learn applies the Z-score normalizaion to the input \"X_original\"\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = pd.DataFrame( scaler.fit_transform(X_original) )\n",
    "X_scaled.columns = X_original.columns;\n",
    "#X_scaled.iloc[:,1:13].describe()\n",
    "\n",
    "Y_scaled = Y_original;\n",
    "data_scaled= pd.concat([X_scaled, Y_scaled], axis=1, join='inner');\n",
    "    \n",
    "formatted_data_scaled = pd.DataFrame()\n",
    "formatted_data_scaled =  pd.melt(data_scaled, [\"default_payment\"], var_name=\"feature\");\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_scaled, Y_scaled,test_size=0.2,shuffle = True,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "D_p = np.unique(y_test, return_counts = True)[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_p * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 32s, sys: 3min 6s, total: 34min 39s\n",
      "Wall time: 25min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_list = [2,4,6,8,10]\n",
    "N_list = [[0.2, 0.5], [0.9,1.1], [1.5, 1.8]]\n",
    "N_list1 = [[0.8,1.2], [0.1,0.8], [0.8, 1.4]]\n",
    "N_list1 = [ [0.1, 0.8], [0.2,0.5] , [0.6, 1.1]  , [0.7, 1] , [0.8, 1.2], [0.8, 1.4], [0.9,1.4] , [1, 1.1],  [1, 1.2] , [1.1,1.3], [1.5, 1.8] ]\n",
    "for N1_ratio,N2_ratio in N_list1:\n",
    "    N1= int(np.unique(y_test, return_counts = True)[1][1] * N1_ratio)\n",
    "    N2= int(np.unique(y_test, return_counts = True)[1][1] * N2_ratio)\n",
    "    \n",
    "    list_con_mat = []\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_number = []\n",
    "    list_precision = []\n",
    "    list_recall = []\n",
    "    list_f1 = []\n",
    "    list_auc = []\n",
    "    list_mcc = []\n",
    "    list_gmean = []\n",
    "    \n",
    "    for p in p_list:\n",
    "        con_mat,cost, number, precision, recall, f1, auc,mcc, gmean = algorithm_nn(N1 = N1,N2 = N2)\n",
    "        list_p.append(p)\n",
    "        list_cost.append(cost)\n",
    "        list_number.append(number)\n",
    "        list_precision.append(precision)\n",
    "        list_recall.append(recall)\n",
    "        list_f1.append(f1)\n",
    "        list_con_mat.append(con_mat)\n",
    "        list_auc.append(auc)\n",
    "        list_mcc.append(mcc)\n",
    "        list_gmean.append(gmean)\n",
    "        \n",
    "    dict = {'p': list_p, 'num1':list_number, 'con_mat':list_con_mat, 'cost': list_cost, 'list_precision':list_precision, 'list_recall':list_recall, 'list_f1':list_f1, 'list_auc': list_auc, 'list_mcc': list_mcc, 'list_gmean': list_gmean}   \n",
    "\n",
    "    df = pd.DataFrame(dict) \n",
    "    method = 'nn'\n",
    "    # saving the dataframe \n",
    "    df.to_csv('result/case2/result_{}_{}_{}.csv'.format(method,N1,N2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, roc_auc_score, roc_curve, f1_score, precision_score, recall_score, matthews_corrcoef\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tempfile\n",
    "import copy\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from random import SystemRandom    \n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "c_10 = 1\n",
    "c_01 = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "def algorithm(X_train,y_train,X_test,y_test, initial_p, times, print_per_num, total_run, N1, N2):\n",
    "    \n",
    "\n",
    "    #initiate\n",
    "    list_minp = []\n",
    "    list_mincost = []\n",
    "    list_num1 = []\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_opt_cost = []\n",
    "    list_precision = []\n",
    "    list_recall = []\n",
    "    list_f1 = []\n",
    "    list_point = []\n",
    "    list_conmat = []\n",
    "    list_auc = []\n",
    "    list_mcc = []\n",
    "    list_gmean = []\n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "\n",
    "    y_pred0 = Model(1,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fpr_fnr(y_pred0, y_test)\n",
    "    (interfpr0, interfnr0, threshold,d) = find_cost_intersection(c_01,y_test, fpr, fnr, thresholds)\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "    initial_cost= c_01 * interfnr0 * D_p + c_10 * interfpr0 * D_n\n",
    "\n",
    "    rho = 0.07\n",
    "    b = 1.6\n",
    "\n",
    "    for j in range(times):\n",
    "        p = initial_p\n",
    "        t= 80\n",
    "        alpha = 0.9\n",
    "        C_right = initial_cost\n",
    "        C_left = initial_cost\n",
    "        C_feasible = initial_cost\n",
    "        \n",
    "        num = num+1\n",
    "\n",
    "\n",
    "        p_new = p\n",
    "        p_max = 10\n",
    "        p_min = 0\n",
    "\n",
    "        delta = 0\n",
    "        C_last = 0\n",
    "        delta_rho = 0\n",
    "\n",
    "        # -----------------------------\n",
    "\n",
    "        N =total_run\n",
    "\n",
    "\n",
    "\n",
    "        #print('{} times'.format(j))\n",
    "        \n",
    "        for i in range(1,N+1):\n",
    "            y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "\n",
    "            # 1\n",
    "            fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "            (interfpr, interfnr, threshold,d) = find_cost_intersection(c_01,y_test, fpr, fnr, thresholds)\n",
    "            (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "            number_of_1 = D_n * interfpr + D_p * (1-interfnr)\n",
    "\n",
    "            # 2\n",
    "            # left\n",
    "            if interfpr < interfpr1:\n",
    "\n",
    "                case = 'left'\n",
    "                interfpr = interfpr1\n",
    "                interfnr = interfnr1\n",
    "\n",
    "                C= int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "                C_left = min(C, C_left)\n",
    "\n",
    "\n",
    "            # right\n",
    "            elif interfpr2 < interfpr:\n",
    "\n",
    "                case = 'right'\n",
    "                interfpr = interfpr2\n",
    "                interfnr = interfnr2\n",
    "\n",
    "                C= int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "                C_right = min(C, C_right)\n",
    "\n",
    "\n",
    "            # center\n",
    "            elif interfpr1<= interfpr <= interfpr2:\n",
    "                interfpr, interfnr,thresholds = find_cost_intersection_within(c_01,y_test, fpr, fnr, thresholds,N1,N2)\n",
    "                C= int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "                C_feasible = min(C_feasible, C)\n",
    "                case = 'center'\n",
    "\n",
    "\n",
    "            # 3\n",
    "            t = alpha * t\n",
    "\n",
    "            # 4\n",
    "            C_opt = min(C_left, C_right, C_feasible)\n",
    "\n",
    "            # 5        \n",
    "            delta_C = C - C_last \n",
    "\n",
    "            # 6\n",
    "            probability = (C_right + 0.5 * C_feasible) / (C_right + C_left + C_feasible) \n",
    "\n",
    "            # 9\n",
    "            probability2 = np.exp(-delta_C / t)\n",
    "            if delta_C <= 0 or ( delta_C > 0 and  probability2 > SystemRandom().random() ):\n",
    "\n",
    "                # 7\n",
    "\n",
    "                delta_rho = (1 - rho  ** ( (1 - (i/N) ) ** b ) )\n",
    "                if probability <= SystemRandom().random():\n",
    "                    delta = (p - p_min) *  delta_rho  # 8\n",
    "                    p_new = p - delta\n",
    "                else:\n",
    "                    delta = (p_max - p) * delta_rho   # 8\n",
    "                    p_new = p + delta\n",
    "\n",
    "\n",
    "            C_last = C\n",
    "\n",
    "            list_p.append(p)\n",
    "            list_cost.append(C)\n",
    "            p = p_new\n",
    "        \n",
    "        min_cost = min(list_cost)\n",
    "        min_p = list_p[list_cost.index(min_cost)]\n",
    "        y_pred = Model(min_p,X_train, y_train, X_test, y_test)\n",
    "        fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "        number_of_1,precision,recall,f1, auc,mcc, gmean, con_mat,interfpr,interfnr,cost,opt_cost = metrics(min_p,fpr, fnr, thresholds,N1,N2,X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        \n",
    "        min_p = np.round(min_p,5)\n",
    "        list_minp.append(min_p)\n",
    "        list_mincost.append(cost)\n",
    "        list_opt_cost.append(opt_cost)\n",
    "        list_num1.append(number_of_1)\n",
    "\n",
    "        list_precision.append(precision)\n",
    "        list_recall.append(recall)\n",
    "        list_f1.append(f1)\n",
    "        list_auc.append(auc)\n",
    "        list_mcc.append(mcc)\n",
    "        list_gmean.append(gmean)\n",
    "        \n",
    "        list_point.append((interfpr, interfnr))\n",
    "        list_conmat.append(con_mat)\n",
    "        \n",
    "        \n",
    "    \n",
    "    dict = {'p': list_minp, 'cost': list_mincost, 'num1': list_num1, 'list_conmat': list_conmat, 'list_point': list_point, 'list_precision':list_precision, 'list_recall':list_recall, 'list_f1':list_f1, 'list_auc': list_auc, 'list_mcc': list_mcc, 'list_gmean': list_gmean, 'list_opt_cost':list_opt_cost}\n",
    "    \n",
    "    df = pd.DataFrame(dict) \n",
    "    method = 'ondemand'\n",
    "    # saving the dataframe \n",
    "    df.to_csv('result/case1/result_{}_{}_{}_{}.csv'.format(method,N1,N2,initial_p,))\n",
    "    \n",
    "    \n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "def metrics(p, fpr, fnr, thresholds,N1,N2,X_train, y_train, X_test, y_test):\n",
    "    y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    # 1\n",
    "    (interfpr, interfnr, threshold,d) = find_cost_intersection(c_01, y_test, fpr, fnr, thresholds)\n",
    "    (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "    \n",
    "    interfpr, interfnr, threshold = find_cost_intersection_within(c_01,y_test, fpr, fnr, thresholds,N1,N2)\n",
    "    \n",
    "    y_pred_copy = copy.copy(y_pred)\n",
    "    y_result = np.where(y_pred_copy>threshold,1,0)\n",
    "    \n",
    "    number_of_1 = D_n * interfpr + D_p * (1-interfnr)\n",
    "    number_of_1 = round(number_of_1)\n",
    "    \n",
    "    y_result = np.where(y_pred >= threshold, 1, 0)\n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "    \n",
    "    cost = int(c_01 * interfnr * D_p + c_10 * interfpr * D_n)\n",
    "    optimal_cost = round(c_01 * D_p *d)\n",
    "    \n",
    "\n",
    "    if N2 < number_of_1:\n",
    "        count = 0\n",
    "        ticket = False\n",
    "        sum1 = sum(np.where(y_pred>threshold,1,0))\n",
    "        target = N2 - sum1\n",
    "        y_pred_copy = copy.copy(y_pred)\n",
    "\n",
    "        for j in range(len(y_pred)):\n",
    "            if y_pred[j] == threshold:\n",
    "                y_pred_copy[j] = 1\n",
    "                count +=1\n",
    "\n",
    "            if count == target:\n",
    "                ticket = True\n",
    "                break\n",
    "\n",
    "        if ticket == True:\n",
    "            y_result = np.where(y_pred_copy >threshold,1,0)\n",
    "            con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "            TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "            number_of_1 = FP + TP\n",
    "\n",
    "    if N2 < number_of_1 and N1 < D_p and D_p < N2: #50,150\n",
    "        count = 0\n",
    "        ticket = False\n",
    "        sum1 = sum(np.where(y_pred>threshold,1,0))\n",
    "        target = N2 - sum1\n",
    "        y_pred_copy = copy.copy(y_pred)\n",
    "        cost_list = []\n",
    "        con_mat_list = []\n",
    "\n",
    "        for j in range(len(y_pred)):\n",
    "            if y_pred[j] == threshold:\n",
    "                y_pred_copy[j] = 1\n",
    "                count +=1\n",
    "                y_result = np.where(y_pred_copy >threshold,1,0)\n",
    "                TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "                if FP + TP >N1:\n",
    "                    cost = FP * c_10 + FN * c_01\n",
    "                    con_mat_list.append(confusion_matrix(y_test, y_result).T.flatten().tolist())\n",
    "                    cost_list.append(cost)\n",
    "\n",
    "            if count == target:\n",
    "                ticket = True\n",
    "            break\n",
    "\n",
    "        if ticket == True:\n",
    "            y_result = np.where(y_pred >threshold,1,0)\n",
    "            con_mat = con_mat_list[cost_list.index(min(cost_list))]\n",
    "            cost = min(cost_list)\n",
    "            TN, FN, FP, TP = con_mat\n",
    "            number_of_1 = FP + TP    \n",
    "        \n",
    "    p = round(precision_score(y_test, y_result),3)\n",
    "    r = round(recall_score(y_test, y_result),3)\n",
    "    f = round(f1_score(y_test, y_result),3)\n",
    "    auc = 1- round(roc_auc_score(y_test, y_result),3)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),3)\n",
    "    \n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    \n",
    "    return number_of_1, p,r,f, auc,mcc, gmean, con_mat, interfpr,interfnr,cost,optimal_cost\n",
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "def find_limit_point(fpr, fnr, thresholds,N1,N2):\n",
    "    (interfpr1,interfnr1,threshold1) = (fpr[N1-1], fnr[N1-1], thresholds[N1-1])\n",
    "    (interfpr2,interfnr2,threshold2) = (fpr[N2-1], fnr[N2-1], thresholds[N2-1])\n",
    "    \n",
    "    return (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def find_cost_intersection(c_01,y_test, fpr, fnr, thresholds):\n",
    "    list_distance = []\n",
    "    norm = np.linalg.norm\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "    k =0.000001\n",
    "    for j in range(len(fpr)):\n",
    "        p1 = np.array([0,k])\n",
    "        p2 = np.array([(D_p/D_n)*c_01*k, 0])\n",
    "\n",
    "        p3 = np.array([fpr[j], fnr[j]])\n",
    "\n",
    "        distance = np.abs(norm(np.cross(p2-p1, p1-p3)))/norm(p2-p1)\n",
    "        list_distance.append(distance)\n",
    "    index = list_distance.index(min(list_distance))\n",
    "\n",
    "    return fpr[index], fnr[index], thresholds[index],min(list_distance)\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def find_cost_intersection_within(c_01,y_test, fpr, fnr, thresholds,N1,N2):\n",
    "    \n",
    "    (interfpr1,interfnr1,threshold1) = (fpr[N1-1], fnr[N1-1], thresholds[N1-1])\n",
    "    (interfpr2,interfnr2,threshold2) = (fpr[N2-1], fnr[N2-1], thresholds[N2-1])\n",
    "\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    list_distance = []\n",
    "    norm = np.linalg.norm\n",
    "\n",
    "    k =0.00001\n",
    "    for j in range(N1-1, N2):\n",
    "        p1 = np.array([0,k])\n",
    "        p2 = np.array([(D_p/D_n)*c_01*k, 0])\n",
    "\n",
    "        p3 = np.array([fpr[j], fnr[j]])\n",
    "\n",
    "        distance = np.abs(norm(np.cross(p2-p1, p1-p3)))/norm(p2-p1)\n",
    "        list_distance.append(distance)\n",
    "\n",
    "    index = list_distance.index(min(list_distance))\n",
    "    \n",
    "    return fpr[N1-1 + index], fnr[N1-1 + index], thresholds[N1-1 + index]\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def algorithm_nn(N1,N2):\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    y_pred = Model(1,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    if D_p <= N1:\n",
    "        num = N1\n",
    "    elif N2 <= D_p:\n",
    "        num = N2\n",
    "    elif N1 < D_p < N2:\n",
    "        num = D_p\n",
    "        \n",
    "    th = sorted(y_pred, reverse = True)[num]\n",
    "    y_result = np.where(y_pred>th, 1, 0)\n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10\n",
    "\n",
    " \n",
    "    number = confusion_matrix(y_test, y_result).T[1][1] + confusion_matrix(y_test, y_result).T[1][0]       \n",
    "    p = round(precision_score(y_test, y_result),3)\n",
    "    r = round(recall_score(y_test, y_result),3)\n",
    "    f = round(f1_score(y_test, y_result),3)\n",
    "    auc = round(roc_auc_score(y_test, y_result),3)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),3)\n",
    "    \n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "\n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10 \n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    \n",
    "    return con_mat,cost, number, p, r, f, auc,mcc, gmean\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def algorithm_cs(p, N1,N2):\n",
    "\n",
    "        \n",
    "        \n",
    "    y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "    fpr, fnr, thresholds = fpr_fnr(y_pred, y_test)\n",
    "\n",
    "    \n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "    \n",
    "    if D_p <= N1:\n",
    "        num = N1\n",
    "    elif N2 <= D_p:\n",
    "        num = N2\n",
    "    elif N1 < D_p < N2:\n",
    "        num = D_p\n",
    "    \n",
    "    th = sorted(y_pred, reverse = True)[num]\n",
    "    y_result = np.where(y_pred>th, 1, 0)\n",
    "    TN, FN, FP, TP = confusion_matrix(y_test, y_result).T.flatten()\n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10\n",
    "\n",
    " \n",
    "    number = confusion_matrix(y_test, y_result).T[1][1] + confusion_matrix(y_test, y_result).T[1][0]       \n",
    "    p = round(precision_score(y_test, y_result),3)\n",
    "    r = round(recall_score(y_test, y_result),3)\n",
    "    f = round(f1_score(y_test, y_result),3)\n",
    "    auc = round(roc_auc_score(y_test, y_result),3)\n",
    "    mcc = round(matthews_corrcoef(y_test, y_result),3)\n",
    "    \n",
    "    tpr = TP / (TP+FN)\n",
    "    tnr = TN / (TN+FP)\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    \n",
    "    \n",
    "    cost = confusion_matrix(y_test, y_result).T[0][1] * c_01 + confusion_matrix(y_test, y_result).T[1][0] * c_10 \n",
    "    con_mat = confusion_matrix(y_test, y_result).T.flatten().tolist()\n",
    "    \n",
    "    return con_mat,cost, number, p, r, f, auc,mcc, gmean\n",
    "# ---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def fpr_fnr(y_pred, y_test):\n",
    "    \n",
    "    list_fpr = []\n",
    "    list_fnr = []\n",
    "    list_th = []\n",
    "    y_pred_sort=sorted(y_pred, reverse=True)\n",
    "\n",
    "    for i in range(1,len(y_pred)+1):\n",
    "        th = y_pred_sort[i-1][0]\n",
    "        y_result = np.where(y_pred >= th,1,0)\n",
    "        tn, fn, fp, tp = confusion_matrix(y_test, y_result).T.ravel()\n",
    "        fpr = fp / (tn+fp)\n",
    "        fnr = fn / (tp+fn)\n",
    "\n",
    "        list_fpr.append(fpr)\n",
    "        list_fnr.append(fnr)\n",
    "        list_th.append(th)\n",
    "        \n",
    "    return [list_fpr, list_fnr, list_th]\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# define model\n",
    "\n",
    "def mid_data():\n",
    "    np.random.seed(0)\n",
    "    X =  np.random.rand(20000,12) * 20\n",
    "\n",
    "    y = []\n",
    "    for p in range(len(X)):\n",
    "\n",
    "\n",
    "        a = X[p][0] \n",
    "        b = X[p][1] \n",
    "        c = X[p][2] \n",
    "        d = X[p][3] \n",
    "        e = X[p][4] \n",
    "        f = X[p][5] \n",
    "        \n",
    "        g = math.cos(X[p][6]) * 10\n",
    "        h = math.cos(X[p][7]) * 10\n",
    "        i = math.cos(X[p][8]) * 10\n",
    "        j = math.sin(X[p][9]) * 10\n",
    "        k = math.sin(X[p][10]) * 10\n",
    "        l = math.sin(X[p][11]) * 10\n",
    "\n",
    "        sum_ = a-b+c-d+e-f+g-h+i-j+k-l\n",
    "        result = 1 if sum_ > 0 else 0\n",
    "\n",
    "        y.append(result)\n",
    "\n",
    "    df =  pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "\n",
    "    df_0 = df[df['y'] == 0][:9000]\n",
    "    df_1 = df[df['y'] == 1][:1000]\n",
    "\n",
    "    df__0 = df_0[:7200].append(df_1[:800]).sample(frac = 1).reset_index(drop = True)\n",
    "    df__1 = df_0[7200:].append(df_1[800:]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "    X_train = df__0.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_train = df__0.iloc[:, [-1]].to_numpy()\n",
    "    X_test = df__1.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_test = df__1.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "def easy_data():\n",
    "    np.random.seed(0)\n",
    "    X =  np.random.rand(20000,12) * 20\n",
    "\n",
    "    y = []\n",
    "    for p in range(len(X)):\n",
    "\n",
    "\n",
    "        a = X[p][0] \n",
    "        b = X[p][1] \n",
    "        c = X[p][2] \n",
    "        d = X[p][3] \n",
    "        e = X[p][4] \n",
    "        f = X[p][5] \n",
    "        \n",
    "        g = X[p][6] \n",
    "        h = X[p][7] \n",
    "        i = X[p][8] \n",
    "        j = X[p][9] \n",
    "        k = X[p][10] \n",
    "        l = X[p][11]\n",
    "        \n",
    "\n",
    "        sum_ = a-b+c-d+e-f+g-h+i-j+k-l\n",
    "        result = 1 if sum_ > 0 else 0\n",
    "\n",
    "        y.append(result)\n",
    "\n",
    "    df =  pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "\n",
    "    df_0 = df[df['y'] == 0][:9000]\n",
    "    df_1 = df[df['y'] == 1][:1000]\n",
    "\n",
    "    df__0 = df_0[:7200].append(df_1[:800]).sample(frac = 1).reset_index(drop = True)\n",
    "    df__1 = df_0[7200:].append(df_1[800:]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "    X_train = df__0.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_train = df__0.iloc[:, [-1]].to_numpy()\n",
    "    X_test = df__1.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_test = df__1.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def hard_data():\n",
    "    np.random.seed(0)\n",
    "    X =  np.random.rand(20000,12) * 20\n",
    "\n",
    "    y = []\n",
    "    for p in range(len(X)):\n",
    "\n",
    "\n",
    "        a = math.cos(X[p][0]) * 10\n",
    "        b = math.cos(X[p][1]) * 10\n",
    "        c = math.cos(X[p][2]) * 10\n",
    "        d = math.sin(X[p][3]) * 10\n",
    "        e = math.sin(X[p][4]) * 10\n",
    "        f = math.sin(X[p][5]) * 10 \n",
    "        \n",
    "        g = math.cos(X[p][6]) * 10\n",
    "        h = math.cos(X[p][7]) * 10\n",
    "        i = math.cos(X[p][8]) * 10\n",
    "        j = math.sin(X[p][9]) * 10\n",
    "        k = math.sin(X[p][10]) * 10\n",
    "        l = math.sin(X[p][11]) * 10\n",
    "\n",
    "        sum_ = a-b+c-d+e-f+g-h+i-j+k-l\n",
    "        result = 1 if sum_ > 0 else 0\n",
    "\n",
    "        y.append(result)\n",
    "\n",
    "    df =  pd.DataFrame(X)\n",
    "    df['y'] = y\n",
    "\n",
    "    df_0 = df[df['y'] == 0][:9000]\n",
    "    df_1 = df[df['y'] == 1][:1000]\n",
    "\n",
    "    df__0 = df_0[:7200].append(df_1[:800]).sample(frac = 1).reset_index(drop = True)\n",
    "    df__1 = df_0[7200:].append(df_1[800:]).sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "    X_train = df__0.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_train = df__0.iloc[:, [-1]].to_numpy()\n",
    "    X_test = df__1.iloc[:, [0,1,2,3,4,5,6,7,8,9]].to_numpy()\n",
    "    y_test = df__1.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# -------------------------------------------------------------------------------------  \n",
    "    \n",
    "def reset_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED']=str(1)\n",
    "    tf.random.set_seed(1)\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "def Model(p, X_train,y_train,X_test,y_test):\n",
    "    reset_random_seeds()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[-1], activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train,y_train, epochs=30, shuffle = True, batch_size=32 ,class_weight =  {0: 1, 1: p}, verbose =0)\n",
    "    y_pred = model.predict(X_test, batch_size=32, verbose =0)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "\n",
    "def rough_plt(N1,N2):\n",
    "\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_cost_ = []\n",
    "    list_inter = []\n",
    "    list_opt = []\n",
    "    list_con1 = []\n",
    "    list_con2 = []\n",
    "\n",
    "    D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "    D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "    for p in range(1,10,1):\n",
    "        y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "        print(p)\n",
    "\n",
    "\n",
    "        (interfpr0, interfnr0, thresholds) = find_cost_intersection(c_01,y_test,fpr, fnr, thresholds)\n",
    "        (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "\n",
    "        list_opt.append([interfpr, interfnr])\n",
    "        list_con1.append([interfpr1, interfnr1])\n",
    "        list_con2.append([interfpr2, interfnr2])\n",
    "\n",
    "        cost1 = c_01 * interfnr * D_p + c_10 * interfpr * D_n\n",
    "\n",
    "        if interfpr1 <= interfpr <= interfpr2:\n",
    "            cost = c_01 * interfnr * D_p + c_10 * interfpr * D_n\n",
    "            list_inter.append([interfpr,interfnr])\n",
    "\n",
    "        elif interfpr < interfpr1:\n",
    "            cost = c_01 * interfnr1 * D_p + c_10 * interfpr1 * D_n\n",
    "            list_inter.append([interfpr1,interfnr1])\n",
    "\n",
    "        elif interfpr2 < interfpr:\n",
    "            cost = c_01 * interfnr2 * D_p + c_10 * interfpr2 * D_n\n",
    "            list_inter.append([interfpr2,interfnr2])\n",
    "\n",
    "        list_cost.append(round(cost1))\n",
    "        list_cost_.append(round(cost))\n",
    "        list_p.append(p)\n",
    "\n",
    "    list_rank_p = []\n",
    "    list_rank_cost = []\n",
    "    for i in range(5):\n",
    "        rank = np.where(np.array(list_cost_) == sorted(list_cost_)[i])[0][0]\n",
    "\n",
    "        rank_p = list_p[rank]\n",
    "        rank_cost = list_cost_[rank]\n",
    "\n",
    "        list_rank_p.append(rank_p)\n",
    "        list_rank_cost.append(rank_cost)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(list_p,list_cost, marker='o', label='optimal')\n",
    "    plt.plot(list_p,list_cost_, marker='o', label='constraint')\n",
    "    plt.legend()\n",
    "    plt.title(f'N1:{N1}, N2:{N2}')\n",
    "    plt.xlabel(f'Best:{list_rank_p[:10]} \\n Best:{list_rank_cost[:10]}')\n",
    "    plt.savefig(f'rough {N1}, {N2}')\n",
    "    \n",
    "    return None\n",
    "# -------------------------------------------------------------------------------------   \n",
    "    \n",
    "def precise_plt(p_start, p_end,N1,N2):\n",
    "\n",
    "\n",
    "    list_p = []\n",
    "    list_cost = []\n",
    "    list_cost_ = []\n",
    "    list_inter = []\n",
    "    list_opt = []\n",
    "    list_con1 = []\n",
    "    list_con2 = []\n",
    "\n",
    "    for p in range(p_start,p_end,1):\n",
    "        p = p/100\n",
    "\n",
    "        y_pred = Model(p,X_train, y_train, X_test, y_test)\n",
    "        D_n = np.unique(y_test, return_counts = True)[1][0]\n",
    "        D_p = np.unique(y_test, return_counts = True)[1][1]\n",
    "\n",
    "\n",
    "        (interfpr0, interfnr0, thresholds) = find_cost_intersection(c_01,y_test, fpr, fnr, thresholds)\n",
    "        (interfpr1,interfnr1,threshold1), (interfpr2,interfnr2,threshold2)= find_limit_point(fpr, fnr, thresholds,N1,N2)\n",
    "\n",
    "        list_opt.append([interfpr, interfnr])\n",
    "        list_con1.append([interfpr1, interfnr1])\n",
    "        list_con2.append([interfpr2, interfnr2])\n",
    "\n",
    "        cost1 = c_01 * interfnr * D_p + c_10 * interfpr * D_n\n",
    "\n",
    "        if interfpr1 <= interfpr <= interfpr2:\n",
    "            cost = c_01 * interfnr * D_p + c_10 * interfpr * D_n  \n",
    "            list_inter.append([interfpr,interfnr])\n",
    "\n",
    "        elif interfpr < interfpr1:\n",
    "            cost = c_01 * interfnr1 * D_p + c_10 * interfpr1 * D_n\n",
    "            list_inter.append([interfpr1,interfnr1])\n",
    "\n",
    "        elif interfpr2 < interfpr:\n",
    "            cost = c_01 * interfnr2 * D_p + c_10 * interfpr2 * D_n\n",
    "            list_inter.append([interfpr2,interfnr2])\n",
    "\n",
    "        list_cost.append(round(cost1))\n",
    "        list_cost_.append(round(cost))\n",
    "        list_p.append(p)\n",
    "\n",
    "    list_rank_p = []\n",
    "    list_rank_cost = []\n",
    "    for i in range(10):\n",
    "        rank = list_cost_.index([*set(sorted(list_cost_))][i])\n",
    "\n",
    "        rank_p = list_p[rank]\n",
    "        rank_cost = list_cost_[rank]\n",
    "\n",
    "        list_rank_p.append(rank_p)\n",
    "        list_rank_cost.append(rank_cost)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(list_p,list_cost, marker='o', label='optimal')\n",
    "    plt.scatter(list_p,list_cost_, marker='o', label='constraint')\n",
    "    plt.legend()\n",
    "    plt.title(f'N1:{N1}, N2:{N2}')\n",
    "    plt.xlabel(f'Best:{list_rank_p[:10]} \\n Best:{list_rank_cost[:10]}')\n",
    "    plt.savefig(f'precise {N1}, {N2}')\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
